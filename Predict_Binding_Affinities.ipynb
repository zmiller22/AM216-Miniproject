{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AM216 Miniproject\n",
    "## Topic 3: Predicting Binding Affinities\n",
    "\n",
    "Zachary Miller, Terry Ni\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our model on the KIBA dataset which has 2111 drugs and 229 proteins and 118254 affinity scores. We use the network as given in [this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129291/pdf/bty593.pdf) and 5-fold cross validation. We evaluate out model with MSE loss. \n",
    "\n",
    "![alt text](network.png \"Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import deepchem as dc\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "from deepchem.feat import RDKitDescriptors   \n",
    "import networkx as nx\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a function to convert our sequences to a  categorical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the seq_to_cat function\n",
    "seq_voc = \"ABCDEFGHIKLMNOPQRSTUVWXYZ\"\n",
    "seq_dict = {v:i for i,v in enumerate(seq_voc)}\n",
    "seq_dict_len = len(seq_dict)\n",
    "max_seq_len = 1000\n",
    "def seq_to_cat(prot):\n",
    "    x = np.zeros(max_seq_len)\n",
    "    for i, ch in enumerate(prot[:max_seq_len]): \n",
    "        x[i] = seq_dict[ch]\n",
    "    return x  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the ligands (SMILE strings) and proteins (sequences):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the drugs to be tested \n",
    "fpath = 'data/kiba/'\n",
    "drugs_ = json.load(open(fpath + \"ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "drugs = np.array([ Chem.MolToSmiles(Chem.MolFromSmiles(d),isomericSmiles=True) for d in drugs_.values() ])\n",
    "drugs_2 = np.array([Chem.MolFromSmiles(smile) for smile in drugs ])\n",
    "drugs_ecfp2 = np.array([ Chem.GetMorganFingerprintAsBitVect(m,2) for m in drugs_2 ])\n",
    "\n",
    "drug_scaler = StandardScaler()\n",
    "drug_scaler.fit(drugs_ecfp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the protein dataset in order to find the proper scaling trsnform for the covid_protein\n",
    "proteins_ = json.load(open(fpath + \"proteins.txt\"), object_pairs_hook=OrderedDict)\n",
    "proteins = np.array(list(proteins_.values()))\n",
    "proteins = np.array([seq_to_cat(p) for p in proteins])\n",
    "\n",
    "protein_scaler = StandardScaler()\n",
    "protein_scaler.fit(proteins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the COVID protein that we'll be using the trained model on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the covid protein\n",
    "covid_protein_path = 'data/6Y84_A.fasta.txt'\n",
    "with open(covid_protein_path) as f:\n",
    "    file_txt = f.readlines()\n",
    "    \n",
    "covid_protein_str = ''\n",
    "covid_protein_str = covid_protein_str.join([line.strip() for line in file_txt[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data ready for the model\n",
    "drugs_ecfp2 = drug_scaler.transform(drugs_ecfp2)\n",
    "drugs_ecfp2 = drugs_ecfp2[:,:,np.newaxis]\n",
    "\n",
    "covid_protein = np.array([seq_to_cat(covid_protein_str)])\n",
    "covid_proteins = protein_scaler.transform(np.repeat(covid_protein, 2111, axis=0))\n",
    "covid_proteins = covid_proteins[:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affinity data for training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in affinity data\n",
    "affinity = np.array(pickle.load(open(fpath + \"Y\",\"rb\"), encoding='latin1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in our train/test folds, which are lists of indices that split our data. We prepare them for 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in train/test folds\n",
    "test_fold = json.load(open(fpath + \"folds/train_fold_setting1.txt\"))\n",
    "train_fold=[]\n",
    "for i in range(5):\n",
    "    val_fold=test_fold.pop(i)\n",
    "    test_fold_copy = [ee for e in test_fold for ee in e ]   \n",
    "    train_fold.append(test_fold_copy)\n",
    "    test_fold.insert(i,val_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build and train our model with 5-fold cross validation in the file method1.py, also included in this submission. \n",
    "\n",
    "We use MSE loss, a batch size of 64, and a loss rate of 0.01. We stop our training after 2 epochs in a row with worse validation losses and save the trained model in final_model.h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = keras.models.load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE evaluation of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE results for 5-fold cross validaton:\n",
      " [0.43387262 0.56399456 0.45285764 0.4416108  0.6529016 ]\n"
     ]
    }
   ],
   "source": [
    "# Look at results of cross validation\n",
    "cross_val = np.loadtxt('5_fold_results')\n",
    "print('MSE results for 5-fold cross validaton:\\n',cross_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we apply the model and predict the top drugs might bind to the COVID protein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binding predictions\n",
    "predictions = model.predict([drugs_ecfp2, covid_proteins], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted Drugs\n",
      "\n",
      "Drug CHEMBL291126 has a predicted binding affinity of: [155.24535]\n",
      "Drug CHEMBL1971227 has a predicted binding affinity of: [79.53979]\n",
      "Drug CHEMBL2086760 has a predicted binding affinity of: [75.149315]\n",
      "Drug CHEMBL483525 has a predicted binding affinity of: [74.68852]\n",
      "Drug CHEMBL1822792 has a predicted binding affinity of: [72.61388]\n"
     ]
    }
   ],
   "source": [
    "# Get the drugs with the 5 highest binding affinities\n",
    "drug_dict = json.load(open(fpath + \"ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "drug_names = list(drug_dict.keys())\n",
    "max_idxs = np.argsort(predictions[:,0])[-5:]\n",
    "\n",
    "print('Top 5 predicted Drugs\\n')\n",
    "for idx in max_idxs[::-1]:\n",
    "    idx = int(idx)\n",
    "    affinity = predictions[idx]\n",
    "    drug_name = drug_names[idx]\n",
    "    print(f'Drug {drug_name} has a predicted binding affinity of: {affinity}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
